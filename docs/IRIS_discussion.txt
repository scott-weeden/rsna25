Discussion and Conclusion

We introduce Iris as a novel in-context learning framework that enables versatile 3D medical image segmentation through only reference examples. Given just one image-label pair as a reference, Iris can segment arbitrary target classes in test images without any model modification or retraining. Iris reveals strong performance on in-distribution tasks across 12 diverse datasets. Iris's performance is particularly evident to distribution shifts and novel unseen classes on 7 held-out test datasets. The key design of Iris is a decoupled architecture that enables efficient 3D medical image processing and single-pass multi-class segmentation. Iris's inference strategies are suitable for different practical scenarios, from efficient context ensemble-based data processing, high-accuracy object-level context retrieval, to in-context finetuning. Further, Iris's task encoding module offers an appealing means to automatically discover meaningful anatomical relationships purely from segmentation masks, allowing knowledge transfer across different tasks and imaging modalities without explicit anatomical supervision.

Limitations and future work. While Iris demonstrates promising capabilities, several challenges remain to explore. The diversity of training tasks could impact the out-of-distribution generalization, suggesting a critical need for automated methods to create diverse tasks without manual annotation. Although Iris shows strong adaptability to novel tasks, there remains a performance gap with supervised upper bounds in certain scenarios. Future investigation will focus on narrowing this gap and expanding both training and evaluation schemes to cover a broader spectrum of medical imaging applications.
